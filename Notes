Day1: 16-06-2019

----------------Gradient Descent-------------

By minimizing this loss with respect to the network parameters, we can find configurations where the loss is at a minimum and 
the network is able to predict the correct labels with high accuracy. 

gradient is always points in the direction of fastest change

We find this minimum using a process called gradient descent.

------------Why BackPropogation---------------

For single layer networks, gradient descent is straightforward to implement. 

Training multilayer networks is done through backpropagation which is really just an application of the chain rule from calculus.

Mathematically, this is really just calculating the gradient of the loss with respect to the weights using the chain rule.
We update our weights using this gradient with some learning rate  𝛼 .

-------------------Autograde-------------------------
torch provides a module, autograd, for automatically calculating the gradients of tensors.

If we have tensor we want to calculate gradient for it then Autograd will automatically calculate gradient for us,

we have have top tell that x=tensor.zeros(require_grad=true) to keep track of all the changes so when time comes we can do back 
propogation to calculate gradient.

we can turn it off using "with tensor.no_grade():"

set gradient on and off globally using "torch.set_grad_enabled(True|False)"

Pytorch keeps accumulate gradients, so we need to clear gradient in every training backward passes using "optimizer.zero_grad()"

-------------steps to build model using pytorch------------------
Building step:
1. Build Model
2. define Loss and Optimizer

Training step:
4. Transform and Load:
    1. Transform
    2. Download and Load Training Data
    3. Download and Load Testing Data

5. Passdata to model (Forward Pass to get logits) 
6. Calculate losses
7. Updates hyperparameters using Gradient Decent

Testing step:
8. Test model and  get Accuracy

----------------Why model.eval()?-------------------

During traning we want to use droupout layer to prevent overfitting, but during inference(Testing, Evaluation) we don't use droupout layers
for that we need to use 
model.eval() #to set model in evaluation mode
model.train() #to set model in training mode

Day2: 17-06-2019

The parameters for PyTorch networks are stored in a model's state_dict, we can access it using "model.state_dict()"

Save model para: torch.save(model.state_dict(), 'checkpoint.pth')
Load model para: state_dict = torch.load('checkpoint.pth') #get checkpoint
                 model.load_state_dict(state_dict) #get trained model

Loading the state dict works only if the model architecture is exactly the same as the checkpoint architecture.

This means we need to rebuild the model exactly as it was when trained. Information about the model architecture needs to be saved 
in the checkpoint, along with the state dict. To do this,you build a dictionary with all the information you need to compeletely 
rebuild the model.

Day3 : 19-06-2019
How broadcasting works in pytorch?

for computational reasons if we are nn.CrossEntropyLoss() then we have to pass logits not the probabilities in the function.

Adam vs SGD? Adam has momentum which speeds up the actual fitting process and also adjust learning rate for each of the individual porameters in your model

What should be the matrix is up to the developer what he want to optimize, a lot of time it is accuracy, It can also be top 5 error rate, 
precision recall

nn.NLLLoss(): Negative log liklihood loss

Quick question:> Transforms increases data or not?

-----------------------------------Secure and Private AI----------------------------------

Federate Learning
Differential Privacy: when model learn from sensative data, it should learn what it suppose to learn

-----------------------------------Differential Privacy------------------------------------
Two different kind of privacy which refers to the place where we can add noise:

Local Differential Privacy: Add Noise to each individual data point(user are most protected)
Global Differential Privacy: Add noise to the output of the function

Global Diff. Privacy leads to more accurate result than Local Diff. Privacy
Trusted Curator: Database owner in the Global Diff. privacy.

Diffrential Privacy always requires a form of randomness or noise added to the query to protect from differencing attack,

Randomized Response: Technique used in the social science when trying to learn about the high level trends for taboo behaviour 
Plausible Deniability: 

There are two types of Noise that we can add:
Gaussian Noise and 
Laplacian Noise (works better)

How much Noise should we add?
Function of four things:
1. type of Noise(Gaussian/Laplacian)
2. Sensitivity of query
3. Desired Epsilon
4. Desired Delta

Laplacian Noise:
b= sensitivity(query)/ Epsilon (For Laplacian Delta is always zero) 

If Epsilon is lower, we are increasing the amount of noise we are adding

If we have function with small sensitivity we can add less Noise 

perfect privacy: query from the database return same value even if we remove a person from database

(in the sense of deep Learning): Training a model should return the same model even if we remove any person from database

We have to add adequate Noise because: 
Access Noise heart Model Accuaray
While Less Noise has risk of individual Privacy

Core Assumption of PATE Analysis is all the dataset don't have common data, they all have diffrent partition

PATE analysis, Epsilon level is based on the level of agreement, if agreement is high epsilon should be low and visa versa.
